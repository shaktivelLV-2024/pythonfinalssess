# -*- coding: utf-8 -*-
"""LVADSUSR115-SHAKTIVEL R-FA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1613Klx6IZ9FNAtQ_tMrLB_3o5wuWS4uw
"""

#1
import pandas as pd
df = pd.read_excel('/content/Walmart_Dataset Python_Final_Assessment.xlsx')
print(df.info())
print(df.describe())

#2
print(df.isnull().sum())
#no missing values
df.drop_duplicates(inplace=True)

#3
#sales
print("Salesdata \n")
print("Mean: Sales \n", df['Sales'].mean())
print("Median: Sales \n", df['Sales'].median())
print("Mode: Sales \n", df['Sales'].mode())
print("Range: Sales \n", df['Sales'].max() - df['Sales'].min())
print("Variance: Sales \n", df['Sales'].var())
print("Standard Deviation: Sales \n", df['Sales'].std())


#qty

print("Quantity data \n")
print("Mean: Quantity \n", df['Quantity'].mean())
print("Median: Quantity \n", df['Quantity'].median())
print("Mode: Quantity \n", df['Quantity'].mode())
print("Range: Quantity \n", df['Quantity'].max() - df['Quantity'].min())
print("Variance: Quantity \n", df['Quantity'].var())
print("Standard Deviation: Quantity \n", df['Quantity'].std())


#profit

print("Profit Data \n")
print("Mean: Profit \n", df['Profit'].mean())
print("Median: Profit \n", df['Profit'].median())
print("Mode: Profit \n", df['Profit'].mode())
print("Range: Profit \n", df['Profit'].max() - df['Profit'].min())
print("Variance: Profit \n", df['Profit'].var())
print("Standard Profit: Profit \n", df['Profit'].std())

#4
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

df['Order Date'] = pd.to_datetime(df['Order Date'])
df['Ship Date'] = pd.to_datetime(df['Ship Date'])
df['Order Year'] = pd.to_datetime(df['Order Date']).dt.year



plt.figure(figsize=(12, 8))
sns.barplot(x='Category', y='Sales', data=df,color='r')
plt.title('Sales by Category')
plt.xlabel('Category')
plt.ylabel('Sales')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


salesData = df.groupby('Order Year')['Sales'].sum()
salesData.plot(label='Sales',linestyle='dotted',color='r',marker='o')
profitData = df.groupby('Order Year')['Profit'].sum()
profitData.plot(label='Profit',linestyle='dashed',color='y',marker='o')
plt.grid(True)
plt.legend()
plt.show()


plt.figure(figsize=(12, 8))
sns.boxplot(x='Profit', data=df,color='pink')
plt.title('Distribution of Profit')
plt.xlabel('Profit')
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 8))
sns.scatterplot(x='Quantity', y='Profit', data=df,color='black')
plt.title('Profit vs Quantity')
plt.xlabel('Quantity')
plt.ylabel('Profit')
plt.tight_layout()
plt.show()

#5
df.corr()

#6
numeric_cols = ['Sales', 'Quantity', 'Profit']
df_zscores = df[numeric_cols].apply(lambda x: np.abs((x - x.mean()) / x.std()))

outliers = df_zscores > 3

outliers_data = df[outliers.any(axis=1)]

print("Outliers:")
print(outliers_data)

plt.figure(figsize=(12, 8))
sns.boxplot(data=df[numeric_cols])
plt.title('Boxplot of Sales, Quantity, and Profit')
plt.xlabel('Features')
plt.ylabel('Values')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#7 - Trend Analysis
# i)


salesData = df.groupby('Order Month')['Sales'].sum()
salesData.plot(label='Sales',color='r',marker='o')
profitData = df.groupby('Order Month')['Profit'].sum()
profitData.plot(label='Profit',color='g',marker='o')
plt.grid(True)
plt.legend()
plt.show()

df['Order Month'] = pd.to_datetime(df['Order Date']).dt.month
salesData = df.groupby('Order Year')['Sales'].sum()
salesData.plot(label='Sales',color='y',marker='o')
profitData = df.groupby('Order Year')['Profit'].sum()
profitData.plot(label='Profit',color='b',marker='o')
plt.grid(True)
plt.legend()
plt.show()



# ii)
total_sales = df.groupby(['Order Year', 'Category'])['Sales'].sum().reset_index()
total_sales['Growth'] = total_sales.groupby('Category')['Sales'].pct_change() * 100
most_growth_category = total_sales.groupby('Category')['Growth'].mean().idxmax()
print("Category with the Most Growth in Sales:", most_growth_category)

"""### Theres a abnormal increase in sales and profit during the month of march but in other months its normal.It can be an effect of summer vacations .In year wise graph of sales the profit grows in a simple ratio to the count of sales where as sales is increased in a massive count.

"""

#7 - Customer Analysis
#i)
customer_summary = df.groupby('EmailID').agg({'Order ID': 'nunique', 'Sales': 'sum'}).reset_index()
customer_summary.columns = ['EmailID', 'Quantity', 'TotalSales']

top_customers_by_orders = customer_summary.nlargest(5, 'Quantity')
top_customers_by_sales = customer_summary.nlargest(5, 'TotalSales')

print("Top 5 Customers by Orders Placed:")
print(top_customers_by_orders.set_index('EmailID'))
print("\nTop 5 Customers by Total Sales:")
print(top_customers_by_sales.set_index('EmailID'))

"""Inference -
Customers who spend more , buy less number of products
customers who buy more ,spend less on each product.
which shows that eventhough a customer buy less number of product the value of products is high and viceversa From which we can conclude that both bands of customer are attracted and satisfied by walmart.

"""

#7 - Customer Analysis
#ii)
df['OrderDate'] = pd.to_datetime(df['Order Date'])
df.sort_values(by=['EmailID', 'Order Date'], inplace=True)
df['TimeBetweenOrders'] = df.groupby('EmailID')['Order Date'].diff()
average_time_between_orders = df.groupby('EmailID')['TimeBetweenOrders'].mean()

print("Average Time Between Orders for Each Customer:")
print(average_time_between_orders)
print(average_time_between_orders.mean())

"""#Comprehensive Analysis"""

#average Time between order and delivery
df['TimeBetweenOrderAndDelivery'] = df['Ship Date'] - df['Order Date']
average_time_between_order_and_delivery = df.groupby('Category')['TimeBetweenOrderAndDelivery'].mean()
print(average_time_between_order_and_delivery)

df['TimeBetweenOrderAndDelivery'] = df['Ship Date'] - df['Order Date']
average_time_between_order_and_delivery = df.groupby('EmailID')['TimeBetweenOrderAndDelivery'].mean()
print(average_time_between_order_and_delivery.mean())

"""#### i) As of now the average time taken for the shipment of an order is 8 days and 20 hours.It stands highest for Tables delivery .Improper allocation of resources in supplychain such as large trucks for acrrying the goods and using many linear programming supplychain tools such as shortest route method or Vogels approach to fund the proper demand satisfaction between supply and demand.

#### ii) The geographic distribution of sales is influenced by various factors such as demographics (age, income),economic conditions and local requirements. Insights from these factors can inform targeted marketing by reading the on grpund data from the favours of specific region and understanding the ground level cultural values so that different marketing strategies can be stimulated.
"""

customer_order_amounts = df.groupby('EmailID')['Sales'].sum().reset_index()

top_10_percent = int(len(customer_order_amounts) * 0.1)
high_value_customers = customer_order_amounts.nlargest(top_10_percent, 'Sales')
print(high_value_customers)

customer_order_amounts = df.groupby('EmailID')['Quantity'].sum().reset_index()

top_10_percent = int(len(customer_order_amounts) * 0.1)
high_value_customers = customer_order_amounts.nlargest(top_10_percent, 'Quantity')
print(high_value_customers)

#any function can be passed to give credits to the customer
for index, customer in high_value_customers.iterrows():
  pass

"""### iii) High value customers - sorted out by  purchasing quantity, purchase frequency and purchase amount.The loyalty of the customers can be maintained by providing them memberships ,discounts and offers and timely credits in the company circle."""

